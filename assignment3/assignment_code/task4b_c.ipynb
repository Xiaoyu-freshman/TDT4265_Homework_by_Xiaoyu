{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (224, 224)\n",
      "First conv layer weight shape: torch.Size([64, 3, 7, 7])\n",
      "First conv layer: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Image shape: torch.Size([1, 3, 224, 224])\n",
      "Activation shape: torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "#This .ipynb is for task4b and task4c\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "image = Image.open(\"images/zebra.jpg\")\n",
    "print(\"Image shape:\", image.size)\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "#print(model)\n",
    "first_conv_layer = model.conv1\n",
    "print(\"First conv layer weight shape:\", first_conv_layer.weight.shape)\n",
    "print(\"First conv layer:\", first_conv_layer)\n",
    "\n",
    "# Resize, and normalize the image with the mean and standard deviation\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "image = image_transform(image)[None]\n",
    "print(\"Image shape:\", image.shape)\n",
    "\n",
    "activation = first_conv_layer(image)\n",
    "print(\"Activation shape:\", activation.shape)\n",
    "\n",
    "\n",
    "\n",
    "def torch_image_to_numpy(image: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Function to transform a pytorch tensor to numpy image\n",
    "    Args:\n",
    "        image: shape=[3, height, width]\n",
    "    Returns:\n",
    "        iamge: shape=[height, width, 3] in the range [0, 1]\n",
    "    \"\"\"\n",
    "    # Normalize to [0 - 1.0]\n",
    "    image = image.detach().cpu() # Transform image to CPU memory (if on GPU VRAM)\n",
    "    image = image - image.min()\n",
    "    image = image / image.max()\n",
    "    image = image.numpy()\n",
    "    if len(image.shape) == 2: # Grayscale image, can just return\n",
    "        return image\n",
    "    assert image.shape[0] == 3, \"Expected color channel to be on first axis. Got: {}\".format(image.shape)\n",
    "    image = np.moveaxis(image, 0, 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "indices = [14, 26, 32, 49, 52]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAALqklEQVR4nO3d/4tld33H8ed7ZnfZ3dkNW02abndCoyWkiFBXtgtlQdrUylqD9gd/SEChRcgvVaItiLbQ4j9g7Q+lsGTTphgNYgyIpNGAhjSgMdm41sSNJSzR3a51EmKSndlkd768+8OcyJjMZM7cueecy7vPBwx778zNeb+zO6/7Oefce887MhNJdUwN3YCk8TLUUjGGWirGUEvFGGqpmB1dbHRm7/58y4G3drHpzU0tDlMXCKYHq50Zg9UGWGHA+ivDrU1TDPPq0QsvPc/CpYvr/qV3Euq3HHgrn/rY33Wx6c3NPDdMXWDn9MxgtS8v7h6sNsDl3DVY7ZWFPYPVnhloEfnHk3+/4c/c/ZaKMdRSMYZaKsZQS8UYaqkYQy0VY6ilYgy1VIyhloox1FIxhloqplWoI+J4RPwkIp6JiM903ZSk0W0a6oiYBv4ZeD/wDuDWiHhH141JGk2blfoo8Exmns3MK8A9wIe6bUvSqNqE+hBwbs398833fk1E3BYRj0fE4wsLF8fVn6QtahPq9T6I/YZPhmfmicw8kplHZmb2b78zSSNpE+rzwHVr7s8CF7ppR9J2tQn1Y8ANEfG2iNgF3AJ8vdu2JI1q08sZZeZSRHwc+CYwDdyZmU913pmkkbS6Rllm3g/c33EvksbAd5RJxRhqqRhDLRVjqKViDLVUjKGWijHUUjGGWirGUEvFdDL1kkhW9gwz4pNrloepCyxMzQ1WO3csDVZ7VTe/Sq3M/9ZgpReuDLMuruzc+PfclVoqxlBLxRhqqRhDLRVjqKViDLVUjKGWijHUUjGGWirGUEvFGGqpGEMtFdNm6uWdETEXEU/20ZCk7WmzUv8bcLzjPiSNyaahzsyHgRd66EXSGIztmHrtKNv5hflxbVbSFo0t1GtH2e6b2TeuzUraIs9+S8UYaqmYNi9pfRn4LnBjRJyPiI9135akUbWZT31rH41IGg93v6ViDLVUjKGWijHUUjGGWirGUEvFGGqpGEMtFWOopWI6mT+6ElO8OrW7i01vXntquJGue649N1jtAwf/Z7DaAFdWFger/eK5GwervfLSwWEKT2/8e+5KLRVjqKViDLVUjKGWijHUUjGGWirGUEvFGGqpGEMtFWOopWIMtVSMoZaKaXPd7+si4jsRcSYinoqI2/toTNJo2nxKawn4m8x8IiL2A6ci4sHM/HHHvUkaQZtRtj/PzCea2xeBM8ChrhuTNJotHVNHxPXAYeDRdX72q1G2CwsXx9OdpC1rHeqI2AfcC3wyM19+/c/XjrKdmdk/zh4lbUGrUEfETlYDfXdmfq3bliRtR5uz3wGcBM5k5ue7b0nSdrRZqY8BHwVuiojTzdefddyXpBG1GWX7CBA99CJpDHxHmVSMoZaKMdRSMYZaKsZQS8UYaqkYQy0VY6ilYgy1VEwno2wTWB7o6WJlzxs+QNabmYM/G6z2wd/77mC1AXbvGa722Z3DjS/+5bnpQerGjo1HB7tSS8UYaqkYQy0VY6ilYgy1VIyhloox1FIxhloqxlBLxRhqqRhDLRVjqKVi2lzMf3dEfD8iftiMsv1cH41JGk2bT2ldBm7KzPlm/M4jEfEfmfm9jnuTNII2F/NPYL65u7P5yi6bkjS6tgPypiPiNDAHPJiZbzrK9pKjbKXBtAp1Zi5n5ruAWeBoRLxzncf8apTtXkfZSoPZ0tnvzHwReAg43kk3kratzdnvayLiQHN7D/Be4OmuG5M0mjZnvw8Cd0XENKtPAl/JzG9025akUbU5+/1fwOEeepE0Br6jTCrGUEvFGGqpGEMtFWOopWIMtVSMoZaKMdRSMYZaKsZQS8V0Mp8akuXljefndmrAyzesLA33HLn46nAzmgGWFlcGq724tHOw2q8sdhShTaxkbPgzV2qpGEMtFWOopWIMtVSMoZaKMdRSMYZaKsZQS8UYaqkYQy0VY6ilYlqHupmn9YOI8Jrf0gTbykp9O3Cmq0YkjUfbqZezwAeAO7ptR9J2tV2pvwB8Gtjw83WOspUmQ5sBeTcDc5l56s0e5yhbaTK0WamPAR+MiGeBe4CbIuKLnXYlaWSbhjozP5uZs5l5PXAL8O3M/EjnnUkaia9TS8Vs6QJLmfkQ8FAnnUgaC1dqqRhDLRVjqKViDLVUjKGWijHUUjGGWirGUEvFGGqpGEMtFdPJHM6plWn2vrKvi01vavnlQ4PUBbj8s+Hm6F54ZbhxrgCvLm88WrVrv/zFHwxW+5WFtw9Sd2Vp46uKuVJLxRhqqRhDLRVjqKViDLVUjKGWijHUUjGGWirGUEvFGGqpGEMtFdPqvd/NdI6LwDKwlJlHumxK0ui28oGOP87M5zvrRNJYuPstFdM21Al8KyJORcRt6z1g7SjbhUsvj69DSVvSdvf7WGZeiIjfBB6MiKcz8+G1D8jME8AJgNnf/t3hPlgs/T/XaqXOzAvNn3PAfcDRLpuSNLo2Q+dnImL/a7eB9wFPdt2YpNG02f2+FrgvIl57/Jcy84FOu5I0sk1DnZlngd/voRdJY+BLWlIxhloqxlBLxRhqqRhDLRVjqKViDLVUjKGWijHUUjGGWiqmk1G2rCRTl5Y62fRmdr00SFkAcuk3Bqu9eOXwYLUBFi7vGqz24vwNg9W+9OrVg9RdWd54dLErtVSMoZaKMdRSMYZaKsZQS8UYaqkYQy0VY6ilYgy1VIyhloox1FIxrUIdEQci4qsR8XREnImIP+y6MUmjafuBjn8CHsjMD0fELmBvhz1J2oZNQx0RVwHvAf4CIDOvAFe6bUvSqNrsfr8deA7414j4QUTc0czU+jWOspUmQ5tQ7wDeDfxLZh4GFoDPvP5BmXkiM49k5pGZvVeNuU1JbbUJ9XngfGY+2tz/KqshlzSBNg11Zv4vcC4ibmy+9SfAjzvtStLI2p79/gRwd3Pm+yzwl921JGk7WoU6M08DRzruRdIY+I4yqRhDLRVjqKViDLVUjKGWijHUUjGGWirGUEvFGGqpGEMtFROZOf6NRjwH/HTE//xq4PkxtmNta1es/TuZec16P+gk1NsREY9n5iDvM7e2tSvUdvdbKsZQS8VMYqhPWNva1h7dxB1TS9qeSVypJW2DoZaKmahQR8TxiPhJRDwTEW+4DHGHde+MiLmIeLKvmmtqXxcR32nGGT0VEbf3WHt3RHw/In7Y1P5cX7XX9DDdXE/+Gz3XfTYifhQRpyPi8Z5rdzrGamKOqSNiGvhv4E9ZvSzxY8Ctmdn5lUsj4j3APPDvmfnOruu9rvZB4GBmPhER+4FTwJ/39P8dwExmzkfETuAR4PbM/F7Xtdf08NesXv/uqsy8uce6zwJHMrP3N59ExF3Af2bmHa+NscrMF8e1/UlaqY8Cz2Tm2Wa0zz3Ah/oonJkPAy/0UWud2j/PzCea2xeBM8ChnmpnZs43d3c2X709y0fELPAB4I6+ag5tzRirk7A6xmqcgYbJCvUh4Nya++fp6Zd7UkTE9cBh4NE3f+RYa05HxGlgDnhwzdCGPnwB+DSw0mPN1yTwrYg4FRG39Vi31Rir7ZikUMc635uMY4MeRMQ+4F7gk5nZ2zCyzFzOzHcBs8DRiOjl8CMibgbmMvNUH/XWcSwz3w28H/ir5hCsD63GWG3HJIX6PHDdmvuzwIWBeulVczx7L3B3Zn5tiB6aXcCHgOM9lTwGfLA5tr0HuCkivthTbTLzQvPnHHAfq4d/feh8jNUkhfox4IaIeFtz8uAW4OsD99S55mTVSeBMZn6+59rXRMSB5vYe4L3A033UzszPZuZsZl7P6r/1tzPzI33UjoiZ5qQkza7v+4BeXvnoY4xV27E7ncvMpYj4OPBNYBq4MzOf6qN2RHwZ+CPg6og4D/xDZp7sozarK9ZHgR81x7YAf5uZ9/dQ+yBwV/PKwxTwlczs9aWlgVwL3Lf6fMoO4EuZ+UCP9TsdYzUxL2lJGo9J2v2WNAaGWirGUEvFGGqpGEMtFWOopWIMtVTM/wF5LRxArw6o1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in indices:\n",
    "    image1=torch_image_to_numpy(activation[0,i,:,:])\n",
    "    plt.imshow(image1)\n",
    "    plt.savefig('Activation_'+str(i)+'.png')\n",
    "    filter_weight=torch_image_to_numpy(first_conv_layer.weight[i,:,:,:])\n",
    "    plt.imshow(filter_weight)\n",
    "    plt.savefig('Filter_weight_'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Task4c by Xiaoyu Zhu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model = nn.Sequential(*list(model.children())[:-2]) \n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation shape: torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "activation_last=new_model(image)\n",
    "print(\"Activation shape:\", activation_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    image2=torch_image_to_numpy(activation_last[0,i,:,:])\n",
    "    plt.imshow(image2)\n",
    "    plt.savefig('Activation_Last_'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
